<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on dev.touyu.me</title><link>https://dev.touyu.me/posts/</link><description>Recent content in Posts on dev.touyu.me</description><generator>Hugo -- gohugo.io</generator><language>ja</language><lastBuildDate>Sun, 11 Oct 2020 22:18:19 +0900</lastBuildDate><atom:link href="https://dev.touyu.me/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>CartoonGAN: Generative Adversarial Networks for Photo Cartoonization</title><link>https://dev.touyu.me/posts/cartoongan/</link><pubDate>Sun, 11 Oct 2020 22:18:19 +0900</pubDate><guid>https://dev.touyu.me/posts/cartoongan/</guid><description>Paper Link
Abstruct 既存手法（Style Transfer, CycleGAN)では、実写画像のアニメ調変換においては、十分な結果を得られていない。 VGGのFeature Mapを用いたContent Lossと、明確なエッジを生成するためのAdversarial Lossの２つの効果的な損失関数を提案。
Architecture Loss function $$ \mathcal{L}(G, D)=\mathcal{L}_{a d v}(G, D)+\omega \mathcal{L}_{c o n}(G, D) \tag{2} $$
StyleとContentのバランスが良い状態になるのは、$\omega=10$
Adversarial loss $$ \begin{aligned} \mathcal{L}_{a d v}(G, D) &amp;amp;=\mathbb{E}_{c_{i} \sim S_{d a t a}(c)}\left[\log D\left(c_{i}\right)\right] \\
&amp;amp;+\mathbb{E}_{e_{j} \sim S_{d a t a}(e)}\left[\log \left(1-D\left(e_{j}\right)\right)\right] \\
&amp;amp;+\mathbb{E}_{p_{k} \sim S_{d a t a}(p)}\left[\log \left(1-D\left(G\left(p_{k}\right)\right)\right)\right] \\
\end{aligned} \tag{3} $$
生成される画像のエッジを明確なものにするために、
通常の訓練画像 → true エッジをぼかした訓練画像 → false 生成画像 → false でDiscriminatorを学習させる</description></item></channel></rss>